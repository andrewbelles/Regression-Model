#include "../include/neural.hpp"
#include <cuda_runtime_api.h>
#include <iostream>
#include <random>
#include <vector>

float tanh_derivative(float x) {
  return 1.0 - (tanh(x) * tanh(x));
}



int main(int argc, char *argv[]) {

  std::random_device rd;
  std::mt19937 gen(rd());
  std::uniform_real_distribution<> distribution(-1,1);


  uint layer_sizes[] = {1,8,8,1};
  uint layer_count   = 3; 
  constexpr uint input_size = 16;
  Activation tanac = {
    .f  = {[](float x) -> float { return tanh(x); }},
    .df = {[](float x) -> float { return 1.0 - (tanh(x) * tanh(x)); }},
    .type = Tanh,
  };

  dim3 blocks(BLOCKSIZE, BLOCKSIZE);
  constexpr dim3 grid((1 + BLOCKSIZE - 1) / BLOCKSIZE, (input_size + BLOCKSIZE - 1) / BLOCKSIZE);

  std::vector<Activation> funcs;
  for (int i = 0; i < 3; i++) {
    funcs.push_back(tanac);
  }

  Network *network = new_network(layer_sizes, layer_count, input_size, funcs);
  
  std::cout << "Created Network\n";

  float *input = new float[16];
  for (int i = 0; i < 16; i++) {
    input[i] = distribution(gen); 
  }

  // Fill matrix with values
  Matrix *input_mat = new_matrix(16, 1);
  fill_matrix<<<grid, blocks>>>(input_mat, input);
  cudaDeviceSynchronize();

  std::cout << "Filled Matrix\n";

  // Test matmul on layers between 
  assert(input_mat->cols() == network->layers[0].weights.rows());
  Matrix *result = matrix_multiplication(input_mat, &network->layers[0].weights);
  std::cout << "First Layer\n";
  assert(result->cols() == network->layers[1].weights.rows());
  Matrix *res2   = matrix_multiplication(result, &network->layers[1].weights);
  assert(res2->cols() == network->layers[2].weights.rows());
  std::cout << "Second Layer\n";
  Matrix *output = matrix_multiplication(res2, &network->layers[2].weights);
  std::cout << "Third Layer\n";
  
  // Print output 
  for (int i = 0; i < output->cols(); i++) {
    std::cout << "[ ";
    for (int j = 0; j < output->rows(); j++) {
      std::cout << output->data[i * output->rows() + j] << " ";
    }
    std::cout << "]\n";
  }

  std::cout << "Network Created\n";

  cudaFree(network);
  cudaFree(input_mat);
  free(input);

  return 0;
}
